{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "missing-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# workaround to import local modules from parent directory\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "from evaluation import mean_average_precision, precision_at_k\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "print('Tensorflow Version: {}'.format(tf.__version__))\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "    \n",
    "DATA_PATH_FORMATED_TRAIN = '../data/GermanFakeNC_FORMATED_TRAIN.json'\n",
    "DATA_PATH_FORMATED_TEST = '../data/GermanFakeNC_FORMATED_TEST.json'\n",
    "DATA_PATH_PROCESSED = '../data/GermanFakeNC_PROCESSED'\n",
    "MODEL_PATH_BERT = '../models/bert-base-german-cased/'\n",
    "MODEL_PATH_BERT_TUNED = '../models/bert-base-german-cased-tuned/checkpoint.ckpt'\n",
    "MODEL_PATH_BERT_TUNED_RANKING = '../models/bert-base-german-cased-tuned-ranking/checkpoint.ckpt'\n",
    "MODEL_PATH_BERT_TUNED_TRUENEWS = '../models/bert-base-german-cased-tuned-truenews/checkpoint.ckpt'\n",
    "DATASET_SIZE = 14765\n",
    "DATASET_DEV_SPLIT = 0.8\n",
    "NUM_SAMPLING_CANDIDATES = 5\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 134\n",
    "LEARNING_RATE = 5e-5\n",
    "BINACC_THRESHOLD = 0.1\n",
    "PRECISION_RECALL_THRESHOLDS = [0.05, 0.1, 0.2, 0.5]\n",
    "EPOCHS = 5\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "developing-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_feature = tf.io.FixedLenFeature([MAX_LEN], dtype=tf.int64)\n",
    "\n",
    "def input_parser_train(example):\n",
    "    feature_description = {'input_ids': bert_feature,\n",
    "                           'token_type_ids': bert_feature,\n",
    "                           'attention_mask': bert_feature,\n",
    "                           'y': tf.io.FixedLenFeature([1], dtype=tf.float32)}\n",
    "\n",
    "    parsed = tf.io.parse_single_example(example, feature_description)\n",
    "    inp = {'input_ids': parsed['input_ids'],\n",
    "           'token_type_ids': parsed['token_type_ids'],\n",
    "           'attention_mask': parsed['attention_mask'],}\n",
    "    return (inp, parsed['y'])\n",
    "\n",
    "def input_parser_test(example):\n",
    "    feature_description = {'article_id': tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "                           'input_ids': bert_feature,\n",
    "                           'token_type_ids': bert_feature,\n",
    "                           'attention_mask': bert_feature,\n",
    "                           'y': tf.io.FixedLenFeature([1], dtype=tf.float32)}\n",
    "\n",
    "    parsed = tf.io.parse_single_example(example, feature_description)\n",
    "    inp = {'input_ids': parsed['input_ids'],\n",
    "           'token_type_ids': parsed['token_type_ids'],\n",
    "           'attention_mask': parsed['attention_mask']}\n",
    "    return (parsed['article_id'][0], inp, parsed['y'][0])\n",
    "\n",
    "def input_parser_cs(example):\n",
    "    feature_description = {'input_ids1': bert_feature,\n",
    "                           'token_type_ids1': bert_feature,\n",
    "                           'attention_mask1': bert_feature,\n",
    "                           'input_ids2': bert_feature,\n",
    "                           'token_type_ids2': bert_feature,\n",
    "                           'attention_mask2': bert_feature,\n",
    "                           'y': tf.io.FixedLenFeature([1], dtype=tf.float32)}\n",
    "\n",
    "    parsed = tf.io.parse_single_example(example, feature_description)\n",
    "    inp = {'input_ids1': parsed['input_ids1'],\n",
    "           'token_type_ids1': parsed['token_type_ids1'],\n",
    "           'attention_mask1': parsed['attention_mask1'],\n",
    "           'input_ids2': parsed['input_ids2'],\n",
    "           'token_type_ids2': parsed['token_type_ids2'],\n",
    "           'attention_mask2': parsed['attention_mask2']}\n",
    "    return (inp, parsed['y'])\n",
    "\n",
    "def format_ranking_dataset(dataset):    \n",
    "    train_dataset_size = int(DATASET_SIZE * NUM_SAMPLING_CANDIDATES * DATASET_DEV_SPLIT)\n",
    "    train_dataset = train_sampling_dataset.map(lambda inp, y: (inp, {'out_s1': y,'out_diff': y}))\n",
    "    # use half the batch size because of memory concerns\n",
    "    train_dataset_split = train_sampling_dataset.take(train_dataset_size).batch(int(BATCH_SIZE / 2)).prefetch(1)\n",
    "    dev_dataset = train_sampling_dataset.skip(train_dataset_size).batch(BATCH_SIZE)    \n",
    "    return train_dataset_split, dev_dataset\n",
    "\n",
    "train_dataset = read_tfrecords(DATA_PATH_PROCESSED, 'TRAIN_BERT_BASE', input_parser_train)\n",
    "train_sampling_dataset = read_tfrecords(DATA_PATH_PROCESSED, 'TRAIN_BERT_SAMPLING', input_parser_cs)\n",
    "train_truenews_dataset = read_tfrecords(DATA_PATH_PROCESSED, 'TRAIN_BERT_TRUENEWS', input_parser_cs)\n",
    "test_dataset = read_tfrecords(DATA_PATH_PROCESSED, 'TEST_BERT_BASE', input_parser_test)\n",
    "\n",
    "num_train_examples = int(DATASET_SIZE * DATASET_DEV_SPLIT)\n",
    "train_ds_split = train_dataset.take(num_train_examples)\n",
    "train_ds_split = train_ds_split.shuffle(100, reshuffle_each_iteration=True).batch(BATCH_SIZE)\n",
    "dev_ds_split = train_dataset.skip(num_train_examples).batch(BATCH_SIZE)\n",
    "\n",
    "train_sampling_dataset_split, dev_sampling_dataset = format_ranking_dataset(train_sampling_dataset)\n",
    "train_truenews_dataset_split, dev_truenews_dataset = format_ranking_dataset(train_sampling_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-initial",
   "metadata": {},
   "source": [
    "### Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbert_model = load_bert_model(MODEL_PATH_BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-palace",
   "metadata": {},
   "source": [
    "### Load ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coral-sunset",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../models/bert-base-german-cased/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fad780b4580>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fad780b4580>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "cbert_model = load_bert_model(MODEL_PATH_BERT)\n",
    "\n",
    "def cbert_model_forward(inp):\n",
    "    outputs = cbert_model(inp)\n",
    "    return outputs.logits\n",
    "\n",
    "shape=(MAX_LEN,)\n",
    "input_type=tf.int32\n",
    "\n",
    "input_ids1 = Input(shape=shape, name='input_ids1', dtype=input_type)\n",
    "attention_mask1 = Input(shape=shape, name='attention_mask1', dtype=input_type)\n",
    "token_type_ids1 = Input(shape=shape, name='token_type_ids1', dtype=input_type)\n",
    "\n",
    "input_ids2 = Input(shape=shape, name='input_ids2', dtype=input_type)\n",
    "attention_mask2 = Input(shape=shape, name='attention_mask2', dtype=input_type)\n",
    "token_type_ids2 = Input(shape=shape, name='token_type_ids2', dtype=input_type) \n",
    "\n",
    "cbert_model_ranking = build_ranking_model(cbert_model_forward,\n",
    "                                          [input_ids1, attention_mask1, token_type_ids1],\n",
    "                                          [input_ids2, attention_mask2, token_type_ids2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-interstate",
   "metadata": {},
   "source": [
    "### Training without ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "precision = tf.keras.metrics.Precision(thresholds=PRECISION_RECALL_THRESHOLDS)\n",
    "recall = tf.keras.metrics.Recall(thresholds=PRECISION_RECALL_THRESHOLDS)\n",
    "binacc = tf.keras.metrics.BinaryAccuracy(threshold=BINACC_THRESHOLD)\n",
    "metrics = [precision, recall, binacc]\n",
    "cbert_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "checkpoint_callback = get_checkpoint_callback(MODEL_PATH_BERT_TUNED, 'val_binary_accuracy', weights_only=True)\n",
    "tensorboard_callback = get_tensorboard_callback('logs')\n",
    "\n",
    "%tensorboard --logdir logs --bind_all\n",
    "history = cbert_model.fit(train_ds_split,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=dev_ds_split,\n",
    "                callbacks=[checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-maldives",
   "metadata": {},
   "source": [
    "### Training with ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "metropolitan-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "precision = tf.keras.metrics.Precision(thresholds=PRECISION_RECALL_THRESHOLDS)\n",
    "recall = tf.keras.metrics.Recall(thresholds=PRECISION_RECALL_THRESHOLDS)\n",
    "binacc = tf.keras.metrics.BinaryAccuracy(threshold=BINACC_THRESHOLD)\n",
    "metrics = {'out_s1': [precision, recall, binacc]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "designed-geography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-152780cdcb2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tensorboard_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorboard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--logdir logs --bind_all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m history = cbert_model_ranking.fit(train_sampling_dataset_split,\n\u001b[1;32m      7\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2335\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2336\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2337\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36m_start_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_start_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(args_string)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mparsed_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mstart_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStartLaunched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorboard/manager.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(arguments, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0mend_time_seconds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_time_seconds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend_time_seconds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval_seconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0msubprocess_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubprocess_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cbert_model_ranking.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "checkpoint_callback = get_checkpoint_callback(MODEL_PATH_BERT_TUNED_RANKING, 'val_binary_accuracy', weights_only=True)\n",
    "tensorboard_callback = get_tensorboard_callback('logs')\n",
    "\n",
    "%tensorboard --logdir logs --bind_all\n",
    "history = cbert_model_ranking.fit(train_sampling_dataset_split,\n",
    "                epochs=1,\n",
    "                validation_data=dev_sampling_dataset,\n",
    "                callbacks=[checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "known-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbert_model = cbert_model_ranking.get_layer(name='tf_bert_for_sequence_classification')\n",
    "cbert_model.save_weights(MODEL_PATH_BERT_TUNED_RANKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continued-aruba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5fc2b22df34cc05e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5fc2b22df34cc05e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "   3429/Unknown - 84256s 25s/step - loss: 0.9389 - out_s1_loss: 0.2817 - out_diff_loss: 0.6572 - out_s1_precision: 0.1119 - out_s1_recall: 0.3980 - out_s1_binary_accuracy: 0.5312WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "3429/3429 [==============================] - 84269s 25s/step - loss: 0.9389 - out_s1_loss: 0.2817 - out_diff_loss: 0.6572 - out_s1_precision: 0.1119 - out_s1_recall: 0.3980 - out_s1_binary_accuracy: 0.5313\n",
      "WARNING:tensorflow:Can save best model only with val_binary_accuracy available, skipping.\n"
     ]
    }
   ],
   "source": [
    "cbert_model_truenews = cbert_model_ranking\n",
    "cbert_model_truenews.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "checkpoint_callback = get_checkpoint_callback(MODEL_PATH_BERT_TUNED_TRUENEWS, 'val_binary_accuracy', weights_only=True)\n",
    "tensorboard_callback = get_tensorboard_callback('logs')\n",
    "\n",
    "%tensorboard --logdir logs --bind_all\n",
    "history = cbert_model_truenews.fit(train_truenews_dataset_split,\n",
    "                epochs=1,\n",
    "                validation_data=dev_truenews_dataset,\n",
    "                callbacks=[checkpoint_callback, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accessory-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbert_model = cbert_model_truenews.get_layer(name='tf_bert_for_sequence_classification')\n",
    "cbert_model.save_weights(MODEL_PATH_BERT_TUNED_TRUENEWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-assurance",
   "metadata": {},
   "source": [
    "### Load fine-tuned BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worthy-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1cc83c32e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbert_model = load_bert_model(MODEL_PATH_BERT)\n",
    "cbert_model.load_weights(MODEL_PATH_BERT_TUNED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-christianity",
   "metadata": {},
   "source": [
    "### Load fine-tuned BERT model + ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbert_model = load_bert_model(MODEL_PATH_BERT)\n",
    "cbert_model.load_weights(MODEL_PATH_BERT_TUNED_RANKING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-athletics",
   "metadata": {},
   "source": [
    "### Load fine-tuned BERT model + truenews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "french-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../models/bert-base-german-cased/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0f50780ac0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbert_model = load_bert_model(MODEL_PATH_BERT)\n",
    "cbert_model.load_weights(MODEL_PATH_BERT_TUNED_TRUENEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minor-generation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0fd41bc580>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f0fd41bc580>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "BERT/MAP: 0.3324119192396223\n",
      "BERT/P@1: 0.21649484536082475\n",
      "BERT/P@5: 0.13608247422680408\n",
      "BERT/P@10: 0.12072901325478631\n"
     ]
    }
   ],
   "source": [
    "def prediction_func(inps):\n",
    "    outputs = cbert_model.predict(inps)\n",
    "    return [l[0] for l in outputs.logits]\n",
    "\n",
    "eval_data_bert = batch_predict(test_dataset, 100, prediction_func)\n",
    "print('BERT/MAP: {}'.format(mean_average_precision(eval_data_bert)))\n",
    "for k in [1, 5, 10]:\n",
    "\n",
    "    print('BERT/P@{}: {}'.format(k, precision_at_k(eval_data_bert, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-sacramento",
   "metadata": {},
   "source": [
    "### Hyperparamerters\n",
    "\n",
    "|     | BERT BASE | BERT SAMPLING | BERT TRUENEWS |\n",
    "|-----|---------|---|---|\n",
    "| BATCH_SIZE |  32  | 16 | 16 |\n",
    "| EPOCHS |     5    | 1 | 1 |\n",
    "\n",
    "### Results\n",
    "|     | BERT BASE | BERT SAMPLING | BERT TRUENEWS |\n",
    "|-----|---------|---|---|\n",
    "| MAP |  0.47965098263440786    | 0.46114418386081657 | 0.3324119192396223 |\n",
    "| P@1 |     0.42857142857142855    | 0.4020618556701031 | 0.21649484536082475 |\n",
    "| P@5 |     0.18571428571428555    | 0.21649484536082456| 0.13608247422680408 |\n",
    "| P@10 |     0.14285714285714268    | 0.15474963181148732 | 0.12072901325478631 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-enforcement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
