{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing models**:\n",
    "- Spacy model: https://github.com/explosion/spacy-models/releases/tag/de_core_news_sm-2.3.0\n",
    "- Word2Vec: Can be trained with the **Word2Vec_10kGNAD** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# workaround to import local modules from parent directory\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import itertools\n",
    "import operator\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K, initializers, regularizers, constraints\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Layer, Dropout, LSTM, Dense, InputLayer\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from evaluation import mean_average_precision, precision_at_k\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "print('Tensorflow Version: {}'.format(tf.__version__))\n",
    "\n",
    "DATA_PATH_PROCESSED = '../data/GermanFakeNC_PROCESSED'\n",
    "NUM_ARTICLES = 489\n",
    "MODEL_NAME = \"CLEF_2019_HANSEN\"\n",
    "MODEL_PATH_BASE = '../models/' + MODEL_NAME + '_BASE'\n",
    "MODEL_PATH_RANKING = '../models/' + MODEL_NAME + '_RANKING'\n",
    "SEED = 12345\n",
    "NUM_SAMPLING_CANDIDATES = 5\n",
    "LSTM_HIDDEN_UNITS = 100\n",
    "EPOCHS = 10\n",
    "CROSS_VALIDATION_K_FOLDS = 19\n",
    "DATASET_SIZE = 14765\n",
    "DATASET_TRAIN_SPLIT = 0.8\n",
    "DATASET_DEV_SPLIT = 0.8\n",
    "BATCH_SIZE = 120\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_parser_train(example):\n",
    "    feature_description = {'x': tf.io.FixedLenFeature([135, 285], dtype=tf.float32),\n",
    "                           'y': tf.io.FixedLenFeature([1], dtype=tf.float32)}\n",
    "\n",
    "    parsed = tf.io.parse_single_example(example, feature_description)\n",
    "    return (parsed['x'],parsed['y'])\n",
    "\n",
    "def input_parser_test(example):\n",
    "    feature_description = {'article_id': tf.io.FixedLenFeature([1], dtype=tf.int64), \n",
    "                           'x': tf.io.FixedLenFeature([135, 285], dtype=tf.float32),\n",
    "                           'y': tf.io.FixedLenFeature([1], dtype=tf.float32)}\n",
    "\n",
    "    parsed = tf.io.parse_single_example(example, feature_description)\n",
    "    return (parsed['article_id'],parsed['x'],parsed['y'])\n",
    "\n",
    "def input_parser_cs(example):\n",
    "    feature_description = {'x': tf.io.FixedLenFeature([135, 285], dtype=tf.float32),\n",
    "                           'y': tf.io.FixedLenFeature([1], dtype=tf.float32),\n",
    "                           'cs': tf.io.FixedLenFeature([135, 285], dtype=tf.float32)}\n",
    "\n",
    "    parsed = tf.io.parse_single_example(example, feature_description)\n",
    "    return (parsed['x'],parsed['y'],parsed['cs'])\n",
    "\n",
    "train_dataset = read_tfrecords(DATA_PATH_PROCESSED, 'TRAIN_BASE', input_parser_train)\n",
    "train_sampling_dataset = read_tfrecords(DATA_PATH_PROCESSED, 'TRAIN_SAMPLING', input_parser_cs)\n",
    "test_dataset = read_tfrecords(DATA_PATH_PROCESSED, 'TEST_BASE', input_parser_test)\n",
    "test_dataset = test_dataset.map(lambda ida, x, y: (ida[0], x, y[0]))\n",
    "\n",
    "# there has already been a train/test data split in preprocessing\n",
    "train_dataset_size = int(DATASET_SIZE * DATASET_TRAIN_SPLIT)\n",
    "\n",
    "train_sampling_dataset_size = int(train_dataset_size * NUM_SAMPLING_CANDIDATES * DATASET_DEV_SPLIT)\n",
    "train_sampling_dataset = train_sampling_dataset.map(lambda x, y, cs: ({'in_s1': x, 'in_s2': cs}, {'out_s1': y,'out_diff': y}))\n",
    "train_sampling_dataset_split = train_sampling_dataset.take(train_sampling_dataset_size).batch(BATCH_SIZE)\n",
    "dev_sampling_dataset = train_sampling_dataset.skip(train_sampling_dataset_size).batch(BATCH_SIZE)\n",
    "\n",
    "train_dataset_size = int(DATASET_SIZE * DATASET_DEV_SPLIT)\n",
    "train_dataset_split = train_dataset.take(train_dataset_size).batch(BATCH_SIZE)\n",
    "dev_dataset = train_dataset.skip(train_dataset_size).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b81de51f46a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = build_base_model(input_shape = (135, 285),\n\u001b[0m\u001b[1;32m      2\u001b[0m                          \u001b[0mhidden_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_HIDDEN_UNITS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                          dropout_prob = DROPOUT)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model.compile(loss='binary_crossentropy',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_base_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = build_base_model(input_shape = (135, 285),\n",
    "                         hidden_units = LSTM_HIDDEN_UNITS,\n",
    "                         dropout_prob = DROPOUT)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "checkpoint_callback = get_checkpoint_callback(MODEL_PATH_BASE, 'val_binary_accuracy')\n",
    "tensorboard_callback = get_tensorboard_callback('logs')\n",
    "\n",
    "history = model.fit(train_dataset_split,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=[checkpoint_callback, tensorboard_callback],\n",
    "            validation_data=dev_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = build_base_model(input_shape=(135, 285),\n",
    "                                      hidden_units=LSTM_HIDDEN_UNITS,\n",
    "                                      dropout_prob=DROPOUT)\n",
    "\n",
    "in_s1 = Input(shape=(None, None), name='in_s1')\n",
    "in_s2 = Input(shape=(None, None), name='in_s2')\n",
    "model = build_ranking_model((lambda inp: base_model(inp)), in_s1, in_s2)\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=[\n",
    "        tf.keras.losses.BinaryCrossentropy(),\n",
    "        RankingError(batch_size=BATCH_SIZE),\n",
    "    ],\n",
    "    loss_weights=[0.5, 0.5],\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
    ")\n",
    "\n",
    "checkpoint_callback = get_checkpoint_callback(MODEL_PATH_RANKING, 'val_out_s1_binary_accuracy')\n",
    "tensorboard_callback = get_tensorboard_callback('logs')\n",
    "\n",
    "history = model.fit(train_sampling_dataset_split,\n",
    "            epochs=2,\n",
    "            callbacks=[checkpoint_callback, tensorboard_callback],\n",
    "            validation_data=dev_sampling_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base model\n",
    "test_model_base = tf.keras.models.load_model(MODEL_PATH_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample prediction for base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    }
   ],
   "source": [
    "# preprocess data\n",
    "false_statement = \"Um die Ermordung unschuldiger Zivilisten in Russland zu üben, sucht die NATO für ihre Manöver russischsprachige Menschen.\"\n",
    "tokens = spacy_model(false_statement)\n",
    "deps = to_deps(tokens, 135)\n",
    "word_vecs = embed([t.text.lower() for t in tokens], 135)\n",
    "inp = np.concatenate((word_vecs, deps), axis=1)\n",
    "print(len(inp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3697008]]\n"
     ]
    }
   ],
   "source": [
    "prediction = test_model_base.predict(np.array( [inp,] ))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ranking model\n",
    "test_model_ranking = tf.keras.models.load_model(MODEL_PATH_RANKING, compile=False)\n",
    "test_model_ranking = test_model_ranking.get_layer(name='base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08147946]]\n"
     ]
    }
   ],
   "source": [
    "prediction = test_model_ranking.predict(np.array( [inp,] ))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base/MAP: 0.3609851566446917\n",
      "Base/P@1: 0.24489795918367346\n",
      "Base/P@5: 0.1734693877551019\n",
      "Base/P@10: 0.13265306122448964\n"
     ]
    }
   ],
   "source": [
    "def prediction_func_base(inps):\n",
    "    return [p[0] for p in test_model_base.predict(inps)]    \n",
    "\n",
    "eval_data_base = batch_predict(test_dataset, 100, prediction_func_base)\n",
    "print('Base/MAP: {}'.format(mean_average_precision(eval_data_base)))\n",
    "for k in [1, 5, 10]:\n",
    "    print('Base/P@{}: {}'.format(k, precision_at_k(eval_data_base, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking/MAP: 0.37321464176223473\n",
      "Ranking/P@1: 0.2653061224489796\n",
      "Ranking/P@5: 0.18775510204081625\n",
      "Ranking/P@10: 0.14483317136378343\n"
     ]
    }
   ],
   "source": [
    "def prediction_func_ranking(inps):\n",
    "    return [p[0] for p in test_model_ranking.predict(inps)]   \n",
    "\n",
    "eval_data_ranking = batch_predict(test_dataset, 100, prediction_func_ranking)\n",
    "print('Ranking/MAP: {}'.format(mean_average_precision(eval_data_ranking)))\n",
    "for k in [1, 5, 10]:\n",
    "    print('Ranking/P@{}: {}'.format(k, precision_at_k(eval_data_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "|     | Base | Ranking |\n",
    "|-----|------|---------|\n",
    "| MAP |   0.3609851566446917   |  0.37321464176223473      |\n",
    "| P@1 |   0.24489795918367346   |    0.2653061224489796     |\n",
    "| P@5 |   0.1734693877551019   |    0.18775510204081625     |\n",
    "| P@10 |   0.13265306122448964   |    0.14483317136378343     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
